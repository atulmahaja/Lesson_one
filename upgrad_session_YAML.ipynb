{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atulmahaja/Lesson_one/blob/main/upgrad_session_YAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IK1-X8VA9aVt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a8483c-d607-4afe-fd29-93f2529e4a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Router Policy Loaded. Logic: High Risk -> Large Model | Low Risk -> Small Model\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "\n",
        "# 1. THE ROUTER POLICY (YAML)\n",
        "# In a real scenario, this is a separate file (router.yaml)\n",
        "router_yaml = \"\"\"\n",
        "policies:\n",
        "  support_chat:\n",
        "    primary: \"small_model\"   # Cost: $0.01\n",
        "    fallback: \"large_model\"  # Cost: $0.10\n",
        "    risk_tier: \"low\"\n",
        "    require_citation: false\n",
        "  policy_qa:\n",
        "    primary: \"large_model\"\n",
        "    fallback: \"human_review\"\n",
        "    risk_tier: \"high\"\n",
        "    require_citation: True\n",
        "  summarization:\n",
        "    primary: \"small_model\"\n",
        "    fallback: \"large_model\"\n",
        "    risk_tier: \"low\"\n",
        "    require_citation: false\n",
        "\n",
        "budget:\n",
        "  max_daily_spend: 5.00\n",
        "  current_spend: 0.00\n",
        "\"\"\"\n",
        "\n",
        "config = yaml.safe_load(router_yaml)\n",
        "print(\"‚úÖ Router Policy Loaded. Logic: High Risk -> Large Model | Low Risk -> Small Model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_cost(model_type, prompt):\n",
        "    # Rough estimate: 1 token per 4 chars.\n",
        "    # Small model: $0.01 per 1k tokens | Large: $0.10 per 1k tokens\n",
        "    tokens = len(prompt) / 4\n",
        "    rate = 0.01 if model_type == \"small_model\" else 0.10\n",
        "    return (tokens / 1000) * rate\n",
        "\n",
        "def route_task(task_type, prompt, budget_state):\n",
        "    policy = config['policies'].get(task_type)\n",
        "\n",
        "    # Decision Logic\n",
        "    selected_model = policy['primary']\n",
        "\n",
        "    # Budget Check: If we are close to the limit, force small model unless high risk\n",
        "    if budget_state > config['budget']['max_daily_spend'] * 0.9:\n",
        "        if policy['risk_tier'] != \"high\":\n",
        "            selected_model = \"small_model\"\n",
        "            print(f\"‚ö†Ô∏è Budget Warning! Routing {task_type} to Small Model.\")\n",
        "\n",
        "    return selected_model\n",
        "\n",
        "# Test the router\n",
        "task = \"support_chat\"\n",
        "p = \"How do I reset my password?\"\n",
        "chosen = route_task(task, p, 0.50)\n",
        "print(f\"‚úÖ Router selected: {chosen} for task {task}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SimWIQ0kAiDz",
        "outputId": "d01b3675-7ecc-4d32-8cf4-6531c0f6bcae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Router selected: small_model for task support_chat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_model(model_name, prompt):\n",
        "    # Simulating model outputs\n",
        "    if model_name == \"small_model\":\n",
        "        return \"Here is your answer.\" # No citation!\n",
        "    if model_name == \"large_model\":\n",
        "        return \"According to the manual [Section 4], here is your answer.\"\n",
        "    return \"ESCALATE_TO_HUMAN\"\n",
        "\n",
        "def run_with_fallback(task_type, prompt):\n",
        "    policy = config['policies'].get(task_type)\n",
        "    model = route_task(task_type, prompt, 0.0)\n",
        "\n",
        "    # First Attempt\n",
        "    response = call_model(model, prompt)\n",
        "\n",
        "    # Quality Gate: Does it require citation?\n",
        "    passed_gate = True\n",
        "    if policy['require_citation'] and \"[\" not in response:\n",
        "        passed_gate = False\n",
        "        print(f\"‚ùå {model} failed Quality Gate (No Citation).\")\n",
        "\n",
        "    # Fallback Logic\n",
        "    if not passed_gate:\n",
        "        fallback_model = policy['fallback']\n",
        "        print(f\"üîÑ Escalating to {fallback_model}...\")\n",
        "        response = call_model(fallback_model, prompt)\n",
        "\n",
        "    return response, \"Success\" if \"[\" in response or not policy['require_citation'] else \"HITL_REQUIRED\"\n",
        "\n",
        "# Execute\n",
        "res, status = run_with_fallback(\"policy_qa\", \"What is the hotel budget?\")\n",
        "print(f\"Final Response: {res} | Status: {status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLUhpEBkAsC5",
        "outputId": "d0dfb345-1ac3-4223-bca2-7a57ff0b8659"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Response: According to the manual [Section 4], here is your answer. | Status: Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\"type\": \"support_chat\", \"q\": \"Where is my order?\"},\n",
        "    {\"type\": \"policy_qa\", \"q\": \"Can I fly Business?\"},\n",
        "    {\"type\": \"summarization\", \"q\": \"Summarize this 10 page doc...\"},\n",
        "    # ... (Imagine 20 varied cases)\n",
        "] * 7 # Multiplied to get to 21 cases\n",
        "\n",
        "log = []\n",
        "total_saved = 0\n",
        "\n",
        "for case in test_cases:\n",
        "    start = time.time()\n",
        "    # Logic to track what we saved vs. always using Large Model\n",
        "    cost_if_large = estimate_cost(\"large_model\", case['q'])\n",
        "\n",
        "    res, status = run_with_fallback(case['type'], case['q'])\n",
        "\n",
        "    actual_cost = estimate_cost(\"small_model\", case['q']) if \"small\" in str(res) else cost_if_large\n",
        "    total_saved += (cost_if_large - actual_cost)\n",
        "\n",
        "    log.append({\n",
        "        \"Task\": case['type'],\n",
        "        \"Status\": status,\n",
        "        \"Cost_Saved\": round(cost_if_large - actual_cost, 4),\n",
        "        \"Latency\": round(time.time()-start, 2)\n",
        "    })\n",
        "\n",
        "# THE SHIPNMENT: Final Leaderboard\n",
        "report = pd.DataFrame(log)\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ROUTER PERFORMANCE REPORT\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Total Model Upgrades (Fallbacks): {len(report[report['Status'] == 'Success'])}\")\n",
        "print(f\"Total Human Escalations (HITL): {len(report[report['Status'] == 'HITL_REQUIRED'])}\")\n",
        "print(f\"ESTIMATED COST SAVED: ${round(total_saved, 2)}\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "id": "Rd1H07WSAxu-",
        "outputId": "953a8eaf-a8de-4f2a-b085-897537de7766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "ROUTER PERFORMANCE REPORT\n",
            "========================================\n",
            "Total Model Upgrades (Fallbacks): 21\n",
            "Total Human Escalations (HITL): 0\n",
            "ESTIMATED COST SAVED: $0.0\n",
            "========================================\n"
          ]
        }
      ]
    }
  ]
}